# -*- coding: utf-8 -*-
"""Gold Price Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XnPslY-blpFJcQYUDtxPogu566g9jOk3

# **[Gold Price Predection ](https://github.com/programmarself/Mentorness-Machine-Learning-Internship-Project-1-Gold-Price-prediction)**

**Batch Name: MIP-ML-07**

<h1 style="font-family: 'poppins'; font-weight: bold; color: Green;">ðŸ‘¨ðŸ’»Author: Irfan Ullah Khan</h1>

[![GitHub](https://img.shields.io/badge/GitHub-Profile-blue?style=for-the-badge&logo=github)](https://github.com/programmarself)
[![Kaggle](https://img.shields.io/badge/Kaggle-Profile-blue?style=for-the-badge&logo=kaggle)](https://www.kaggle.com/programmarself)
[![LinkedIn](https://img.shields.io/badge/LinkedIn-Profile-blue?style=for-the-badge&logo=linkedin)](https://www.linkedin.com/in/irfan-ullah-khan-4a2871208/)  

[![YouTube](https://img.shields.io/badge/YouTube-Profile-red?style=for-the-badge&logo=youtube)](https://www.youtube.com/@irfanullahkhan7748)
[![Email](https://img.shields.io/badge/Email-Contact%20Me-red?style=for-the-badge&logo=email)](mailto:programmarself@gmail.com)
[![Website](https://img.shields.io/badge/Website-Contact%20Me-red?style=for-the-badge&logo=website)](https://datasciencetoyou.odoo.com)

# Installing Dependencies

---
"""

#!pip install numpy

#!pip install pandas

#!pip install seaborn

#!pip install sklearn

#!pip install matplotlib

"""# Importing the Libraries"""

# will hide errors like outdated verisions
import warnings
warnings.filterwarnings('ignore')

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn import metrics

"""# Data Collection and Processing"""

# loading the csv data to a Pandas DataFrame
df = pd.read_csv('gold_price_data.csv')

# print first 5 rows in the dataframe
df.head()

# print last 5 rows of the dataframe
df.tail()

# number of rows and columns
df.shape

# getting some basic informations about the data
df.info()

# checking the number of missing values in Gold Data
df.isnull().sum()

df.duplicated().sum() # checking the duplicate values in Gold Data

# getting the statistical measures of the Gold data
df.describe()

"""Correlation:
1. Positive Correlation -> Rising values in one variable align with increasing values in another
2. Negative Correlation -> Rising values in one variable align with decreasing values in another
"""

df = data.drop(["GLD"], axis=1)
correlation = df.corr()

# constructing a heatmap to understand the correlatiom
plt.figure(figsize = (8,8))
sns.heatmap(correlation, cbar=True, square=True, fmt='.3f',annot=True, annot_kws={'size':15})

correlation = pd.DataFrame({"SPX": [1, 0.8, 0.7], "USO": [0.8, 1, 0.6], "SLV": [0.7, 0.6, 1], "GLD": [0.5, 0.4, 0.3]})

print(correlation["GLD"])

# checking the distribution of the GLD Price
sns.distplot(data['GLD'],color='red')

"""Splitting the Features and Target"""

print(A)

print(B)

"""Splitting into Training data and Test Data"""

X_train, X_test, Y_train, Y_test = train_test_split(A, B, test_size = 0.2, random_state=42)

"""Model Training:
Random Forest Regressor

#### (n_estimators) represents number of trees in forest. Usually the higher number of trees better to learn data.
"""

regressor = RandomForestRegressor(n_estimators=500)

# training the model
regressor.fit(X_train,Y_train)

"""Model Evaluation"""

# prediction on Test Data
test_data_prediction = regressor.predict(X_test)

print(test_data_prediction)

# R squared error
error_score = metrics.r2_score(Y_test, test_data_prediction)
print("R squared error : ", error_score * 100)

"""Compare the Actual Values and Predicted Values in a Plot"""

Y_test = list(Y_test)

plt.plot(Y_test, color='blue', label = 'Actual Value')
plt.plot(test_data_prediction, color='green', label='Predicted Value')
plt.title('Actual Price vs Predicted Price')
plt.xlabel('Number of values')
plt.ylabel('GLD Price')
plt.legend()
plt.show()